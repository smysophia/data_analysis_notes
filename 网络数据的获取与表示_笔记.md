# 网页下载
```py
import requests
url = 'https://www.baidu.com/'
r_obj = requests.get(url)  # 返回Response的对象

# 查看Response对象(状态码/header/text/...)
# 状态码
r_obj.status_code

# 网页header信息
r_obj.headers

# 网页编码
r_obj.encoding

# 重新设置网页编码
r_obj.encoding = 'utf-8'

# 请求返回的文本信息
r_obj.text

# 以字节形式返回的非文本信息
r_obj.content
```

# 网页解析
实现方式:
* 字符窜匹配:正则表达
* html.parser: py自带的解析html的工具
* BeautifulSoup: 结构化的网页 解析工具

```py
import requests
from bs4 import BeautifulSoup
url = 'http://www.baidu.com'
r_obj = requests.get(url)
bs = BeautifulSoup(r_obj.content, 
                   'lxml',
                   from_encoding='utf-8')

# 查找title标签
link_tag = bs.find('a')
# <a class="mnav" href="http://news.baidu.com" name="tj_trnews">新闻</a>

# 获取节点信息
# 节点标签名称
link_tag.name
# 节点的属性
link_tag.attrs
link_tag['href']
link_tag.text

# 获取表格标签
table_tag = bs_obj.find('table')
# 获取表格的每行内容，即“孩子”节点
for row in table_tag.children:
    print(row)
# 获取子孙节点
for descendant in table_tag.descendants:
    print(descendant)
# 返回下一个“同辈”节点
first_row = table_tag.find('tr')
for sibling in first_row.previous_siblings:
    print(sibling)
# 返回“父亲”节点
first_row.parent
